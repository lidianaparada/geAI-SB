import axios from "axios";
import dotenv from "dotenv";
import readline from "readline";

dotenv.config();

const API_KEY = process.env.NVIDIA_API_KEY;
const MODEL = "meta/llama-3.3-70b-instruct";

// ğŸ—¨ï¸ Guardamos el historial de conversaciÃ³n
const conversation = [
  {
    role: "system",
    content:
      "Eres un asistente de compras para una cafeterÃ­a. Da recomendaciones personalizadas y amables.",
  },
];

// Configuramos la interfaz de lÃ­nea de comandos
const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

// ğŸ” FunciÃ³n principal para enviar y recibir mensajes
async function chat() {
  rl.question("TÃº: ", async (userInput) => {
    if (userInput.toLowerCase() === "salir") {
      console.log("ğŸ‘‹ Â¡Hasta luego!");
      rl.close();
      return;
    }

    // AÃ±adimos el mensaje del usuario al historial
    conversation.push({ role: "user", content: userInput });

    try {
      const response = await axios.post(
        "https://integrate.api.nvidia.com/v1/chat/completions",
        {
          model: MODEL,
          messages: conversation,
          temperature: 0.7,
        },
        {
          headers: {
            Authorization: `Bearer ${API_KEY}`,
            "Content-Type": "application/json",
          },
        }
      );

      const assistantMessage = response.data.choices[0].message.content;

      console.log(`Asistente: ${assistantMessage}\n`);

      // Guardamos tambiÃ©n la respuesta en el historial
      conversation.push({ role: "assistant", content: assistantMessage });
    } catch (error) {
      console.error(
        "âŒ Error:",
        error.response?.status,
        error.response?.data || error.message
      );
    }

    // ğŸ” Continuamos el chat
    chat();
  });
}

// Iniciamos el chat
console.log("â˜• Bienvenido al asistente de cafeterÃ­a (escribe 'salir' para terminar)\n");
chat();
