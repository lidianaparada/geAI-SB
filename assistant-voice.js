import express from "express";
import axios from "axios";
import dotenv from "dotenv";
import cors from "cors";
import multer from "multer";
import FormData from "form-data";

dotenv.config();
const app = express();
app.use(cors());
app.use(express.json());

// Configurar multer para archivos de audio en memoria
const upload = multer({ storage: multer.memoryStorage() });

const NVIDIA_API_KEY = process.env.NVIDIA_API_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const MODEL = "meta/llama-3.3-70b-instruct";

// =========================
// ENDPOINT: Chat con LLM (NVIDIA)
// =========================
app.post("/chat", async (req, res) => {
  const { userInput, history = [] } = req.body;
  const messages = [
    {
      role: "system",
      content:
        "Eres un asistente de compras para Starbucks. Habla espa√±ol, breve y amable. " +
        "Confirma tama√±o (Short/Grande/Venti), leche (entera/deslact/almendra/avena), " +
        "temperatura (fr√≠o/caliente), endulzante (normal/light/sin) y extras. " +
        "Si falta info, haz UNA sola pregunta. Cierra con: RESUMEN: <pedido>."
    },
    ...history,
    { role: "user", content: userInput }
  ];

  try {
    const { data } = await axios.post(
      "https://integrate.api.nvidia.com/v1/chat/completions",
      { model: MODEL, messages, temperature: 0.4 },
      { 
        headers: { 
          Authorization: `Bearer ${NVIDIA_API_KEY}`, 
          "Content-Type": "application/json" 
        } 
      }
    );
    const reply = data?.choices?.[0]?.message?.content?.trim() ?? "(sin respuesta)";
    return res.json({ reply });
  } catch (e) {
    console.error("Error LLM:", e.response?.data || e.message);
    return res.status(500).json({ error: "LLM error" });
  }
});

// =========================
// ENDPOINT: ASR (Audio ‚Üí Texto) con OpenAI Whisper
// =========================
app.post("/transcribe", upload.single("audio"), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: "No se recibi√≥ archivo de audio" });
    }

    console.log("üì• Audio recibido:", req.file.originalname, `(${req.file.size} bytes)`);

    // Crear FormData para OpenAI Whisper
    const formData = new FormData();
    formData.append("file", req.file.buffer, {
      filename: "audio.webm",
      contentType: req.file.mimetype
    });
    formData.append("model", "whisper-1");
    formData.append("language", "es"); // Espa√±ol
    formData.append("response_format", "json");

    console.log("üì§ Enviando a OpenAI Whisper...");

    // OpenAI Whisper endpoint
    const response = await axios.post(
      "https://api.openai.com/v1/audio/transcriptions",
      formData,
      {
        headers: {
          Authorization: `Bearer ${OPENAI_API_KEY}`,
          ...formData.getHeaders()
        },
        timeout: 30000
      }
    );

    const transcript = response.data?.text?.trim() || "";
    console.log("‚úÖ Transcripci√≥n:", transcript);

    return res.json({ transcript });

  } catch (error) {
    console.error("‚ùå Error ASR:");
    console.error("  - Status:", error.response?.status);
    console.error("  - Data:", JSON.stringify(error.response?.data, null, 2));
    console.error("  - Message:", error.message);
    
    return res.status(500).json({ 
      error: "Error en transcripci√≥n",
      details: error.response?.data?.error?.message || error.message,
      status: error.response?.status
    });
  }
});

// =========================
// ENDPOINT: TTS (Texto ‚Üí Audio) con NVIDIA Magpie TTS
// =========================
app.post("/speak", async (req, res) => {
  try {
    const { text, voice = "Magpie-Multilingual.ES-US.Luna" } = req.body;

    if (!text) {
      return res.status(400).json({ error: "Falta el texto a sintetizar" });
    }

    console.log("üîä Generando audio con NVIDIA Magpie TTS...");
    console.log("   Voz:", voice);
    console.log("   Texto:", text.substring(0, 50) + "...");

    // Crear FormData para NVIDIA Magpie TTS
    const formData = new FormData();
    formData.append("text", text);
    formData.append("language", "es-US"); // Espa√±ol
    formData.append("voice", voice);
    
    // Voces disponibles:
    // Espa√±ol: Magpie-Multilingual.ES-US.Luna, Magpie-Multilingual.ES-US.Carlos
    // Ingl√©s: Magpie-Multilingual.EN-US.Sofia, Magpie-Multilingual.EN-US.Ray
    // Franc√©s: Magpie-Multilingual.FR-FR.Camille, Magpie-Multilingual.FR-FR.Pascal
    // Alem√°n: Magpie-Multilingual.DE-DE.Aria, Magpie-Multilingual.DE-DE.Leo

    try {
      // Intentar con NVIDIA Magpie TTS
      const response = await axios.post(
        "https://integrate.api.nvidia.com/v1/audio/speech",
        formData,
        {
          headers: {
            Authorization: `Bearer ${NVIDIA_API_KEY}`,
            ...formData.getHeaders()
          },
          responseType: "arraybuffer",
          timeout: 30000
        }
      );

      console.log("‚úÖ Audio NVIDIA generado");

      // Enviar audio como WAV
      res.set({
        "Content-Type": "audio/wav",
        "Content-Length": response.data.length
      });
      res.send(Buffer.from(response.data));

    } catch (nvidiaError) {
      console.error("‚ùå Error NVIDIA TTS:", nvidiaError.response?.status, nvidiaError.response?.data);
      
      // Fallback a OpenAI TTS si est√° disponible
      if (OPENAI_API_KEY) {
        console.log("‚ö†Ô∏è Fallback a OpenAI TTS...");
        
        const openaiResponse = await axios.post(
          "https://api.openai.com/v1/audio/speech",
          {
            model: "tts-1",
            voice: "nova",
            input: text,
            speed: 1.0
          },
          {
            headers: {
              Authorization: `Bearer ${OPENAI_API_KEY}`,
              "Content-Type": "application/json"
            },
            responseType: "arraybuffer"
          }
        );

        console.log("‚úÖ Audio OpenAI generado (fallback)");

        res.set({
          "Content-Type": "audio/mpeg",
          "Content-Length": openaiResponse.data.length
        });
        res.send(Buffer.from(openaiResponse.data));
      } else {
        throw nvidiaError;
      }
    }

  } catch (error) {
    console.error("‚ùå Error TTS completo:");
    console.error("  - Status:", error.response?.status);
    console.error("  - Message:", error.message);
    
    return res.status(500).json({ 
      error: "Error en s√≠ntesis de voz",
      details: error.response?.data || error.message,
      suggestion: "Verifica tu API key de NVIDIA y que Magpie TTS est√© disponible"
    });
  }
});

// =========================
// ENDPOINT: Flujo completo ASR ‚Üí LLM ‚Üí TTS
// =========================
app.post("/voice-chat", upload.single("audio"), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: "No se recibi√≥ archivo de audio" });
    }

    // 1. Transcribir con OpenAI Whisper
    console.log("üé§ Transcribiendo...");
    const formData = new FormData();
    formData.append("file", req.file.buffer, {
      filename: "audio.webm",
      contentType: req.file.mimetype
    });
    formData.append("model", "whisper-1");
    formData.append("language", "es");

    const asrResponse = await axios.post(
      "https://api.openai.com/v1/audio/transcriptions",
      formData,
      {
        headers: {
          Authorization: `Bearer ${OPENAI_API_KEY}`,
          ...formData.getHeaders()
        }
      }
    );

    const userInput = asrResponse.data?.text?.trim() || "";
    console.log("üìù Usuario dijo:", userInput);

    if (!userInput) {
      return res.status(400).json({ error: "No se pudo transcribir el audio" });
    }

    // 2. Obtener respuesta del LLM (NVIDIA)
    console.log("ü§ñ Generando respuesta...");
    const history = JSON.parse(req.body.history || "[]");
    const messages = [
      {
        role: "system",
        content:
          "Eres un asistente de compras para Starbucks. Habla espa√±ol, breve y amable. " +
          "Confirma tama√±o (Short/Grande/Venti), leche (entera/deslact/almendra/avena), " +
          "temperatura (fr√≠o/caliente), endulzante (normal/light/sin) y extras. " +
          "Si falta info, haz UNA sola pregunta. Cierra con: RESUMEN: <pedido>."
      },
      ...history,
      { role: "user", content: userInput }
    ];

    const llmResponse = await axios.post(
      "https://integrate.api.nvidia.com/v1/chat/completions",
      { model: MODEL, messages, temperature: 0.4 },
      { 
        headers: { 
          Authorization: `Bearer ${NVIDIA_API_KEY}`, 
          "Content-Type": "application/json" 
        } 
      }
    );

    const reply = llmResponse.data?.choices?.[0]?.message?.content?.trim() || "";
    console.log("ü§ñ Asistente responde:", reply);

    if (!reply) {
      return res.status(500).json({ error: "Sin respuesta del LLM" });
    }

    // 3. Convertir respuesta a audio con OpenAI TTS
    console.log("üîä Sintetizando voz...");
    const ttsResponse = await axios.post(
      "https://api.openai.com/v1/audio/speech",
      {
        model: "tts-1",
        voice: "nova",
        input: reply,
        response_format: "mp3"
      },
      {
        headers: {
          Authorization: `Bearer ${OPENAI_API_KEY}`,
          "Content-Type": "application/json"
        },
        responseType: "arraybuffer"
      }
    );

    console.log("‚úÖ Flujo completo exitoso");

    // Retornar todo junto
    return res.json({
      transcript: userInput,
      reply,
      audioBase64: Buffer.from(ttsResponse.data).toString("base64")
    });

  } catch (error) {
    console.error("‚ùå Error en flujo completo:", error.response?.data || error.message);
    return res.status(500).json({ 
      error: "Error en el flujo de voz",
      details: error.response?.data?.error?.message || error.message
    });
  }
});

// =========================
// ENDPOINT: Test de conexi√≥n
// =========================
app.get("/health", (req, res) => {
  res.json({ 
    status: "OK",
    nvidia: NVIDIA_API_KEY ? "‚úì" : "‚úó FALTA",
    openai: OPENAI_API_KEY ? "‚úì" : "‚úó FALTA"
  });
});

const PORT = 3000;
app.listen(PORT, () => {
  console.log(`üöÄ Servidor corriendo en http://localhost:${PORT}`);
  console.log(`üìä Health check: http://localhost:${PORT}/health`);
  console.log(`‚úÖ NVIDIA API: ${NVIDIA_API_KEY ? "Configurada" : "‚ùå FALTA"}`);
  console.log(`‚úÖ OpenAI API: ${OPENAI_API_KEY ? "Configurada" : "‚ùå FALTA"}`);
});